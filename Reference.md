# 神经网络

## RBF（径向基神经网络）

[径向基神经网络RBF](https://blog.csdn.net/ACdreamers/article/details/46327761)

[人工神经网络——径向基函数](https://blog.csdn.net/zb1165048017/article/details/49385359)

[RBF神经网络简单介绍与Matlab实现](https://blog.csdn.net/weiwei9363/article/details/72808496)







# 集成学习

[Adaboost算法的原理及推导](https://blog.csdn.net/v_july_v/article/details/40718799)

[adaboost算法分析和实例+代码](https://blog.csdn.net/guyuealian/article/details/70995333)

[数据挖掘是十大算法详解](https://wizardforcel.gitbooks.io/dm-algo-top10/content/index.html)

[集成学习原理小结](http://www.cnblogs.com/pinard/p/6131423.html)

[Booststrap,Bagging,Boosting](https://www.jianshu.com/p/708dff71df3a)

[集成学习之Adaboost算法原理小结](https://www.cnblogs.com/pinard/p/6133937.html)



# 支持向量机

[支持向量机原理(一) 线性支持向量机](http://www.cnblogs.com/pinard/p/6097604.html)

[支持向量机原理(二) 线性支持向量机的软间隔最大化模型](http://www.cnblogs.com/pinard/p/6100722.html)

[支持向量机原理(三)线性不可分支持向量机与核函数](http://www.cnblogs.com/pinard/p/6103615.html)

[支持向量机原理(四)SMO算法原理](http://www.cnblogs.com/pinard/p/6111471.html)

[支持向量机原理(五)线性支持回归](http://www.cnblogs.com/pinard/p/6113120.html)





# 梯度下降

[梯度下降小结](https://www.cnblogs.com/pinard/p/5970503.html)

[批量梯度下降和随机梯度下降的公式对比及实现对比](https://blog.csdn.net/lilyth_lilyth/article/details/8973972)

[深入浅出-梯度下降法](https://www.jianshu.com/p/c7e642877b0e)





# 主成分分析

[主成分分析（PCA）原理总结](https://www.cnblogs.com/pinard/p/6239403.html)

[主成分分析（PCA）原理详解](https://blog.csdn.net/zhongkelee/article/details/44064401)



# 奇异值分解

[奇异值分解（SVD）原理以及在降维中的应用](https://www.cnblogs.com/pinard/p/6251584.html)

















